{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb42f583bd723c",
   "metadata": {},
   "source": [
    "# Spark Streaming et fenêtres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f9839fa30472a",
   "metadata": {},
   "source": [
    "Use case : Flight tracking with OpenSky"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbc0b0a04a65c8",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e621fd8b6ed4552e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:24.483266Z",
     "start_time": "2025-02-18T12:36:24.479999Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, IntegerType, TimestampType, FloatType, BooleanType\n",
    "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\n",
    "\n",
    "from pyspark.sql.functions import col, desc, sum, mean, min, max, lit, coalesce, bucket, col, window, avg ,count,from_json, when, current_timestamp, countDistinct\n",
    "from matplotlib.pylab import mean\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:24.470024Z",
     "start_time": "2025-02-18T12:36:20.523619Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setAppName(\"SparkApp\") \\\n",
    "    .setMaster(\"spark://spark:7077\") \\\n",
    "    .set(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\") \\\n",
    "    .set(\"spark.sql.shuffle.partitions\", \"10\")\n",
    "\n",
    "# Build the SparkSession using the unified configuration\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Get the SparkContext from the SparkSession (if needed)\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# Create a SQLContext (if needed for legacy operations)\n",
    "sql_context = SQLContext(sc)\n",
    "\n",
    "print(\"SparkSession and SparkContext successfully created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f611568",
   "metadata": {},
   "source": [
    "### Configuration kafka et spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b9cced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:26.412948Z",
     "start_time": "2025-02-18T12:36:24.826668Z"
    }
   },
   "outputs": [],
   "source": [
    "flights_df = sql_context.read.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:9092\") \\\n",
    "    .option(\"subscribe\", \"opensky-flights\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"endingOffsets\", \"latest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846815e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:26.692456Z",
     "start_time": "2025-02-18T12:36:26.483446Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"icao24\", StringType(), True),\n",
    "    StructField(\"firstSeen\", LongType(), True),\n",
    "    StructField(\"estDepartureAirport\", StringType(), True),\n",
    "    StructField(\"lastSeen\", LongType(), True),\n",
    "    StructField(\"estArrivalAirport\", StringType(), True),\n",
    "    StructField(\"estDepartureAirportHorizDistance\", LongType(), True),\n",
    "    StructField(\"estDepartureAirportVertDistance\", LongType(), True),\n",
    "    StructField(\"estArrivalAirportHorizDistance\", LongType(), True),\n",
    "    StructField(\"estArrivalAirportVertDistance\", LongType(), True),\n",
    "    StructField(\"departureAirportCandidatesCount\", LongType(), True),\n",
    "    StructField(\"arrivalAirportCandidatesCount\", LongType(), True)\n",
    "])\n",
    "\n",
    "flights_json = flights_df.select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\")).select(\"data.*\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2e9e2",
   "metadata": {},
   "source": [
    "## Requêtes en mode batch, avec état.\n",
    "### Mode batch avec fenêtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68321e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Kafka messages\n",
    "parsed_stream = flights_df.selectExpr(\"CAST(value AS STRING) AS message\") \\\n",
    "    .select(from_json(col(\"message\"), schema).alias(\"data\")) \\\n",
    "    .select(\n",
    "        col(\"data.lastSeen\").cast(TimestampType()).alias(\"ArrivalTime\"),\n",
    "        col(\"data.estArrivalAirport\").alias(\"Airport\")\n",
    "    )\n",
    "\n",
    "# Compute number of arrivals over a 60-minute window\n",
    "rolling_numbers = parsed_stream \\\n",
    "    .groupBy(window(col(\"ArrivalTime\"), \"60 minutes\")) \\\n",
    "    .count() \\\n",
    "    .select(\n",
    "        col(\"window.start\").alias(\"window_start\"),\n",
    "        col(\"window.end\").alias(\"window_end\"),\n",
    "        col(\"count\").alias(\"num_arrivals\")\n",
    "    ).orderBy(\"window_start\")\n",
    "\n",
    "# Collect the result as a Pandas DataFrame\n",
    "pandas_df = rolling_numbers.toPandas()\n",
    "pandas_df\n",
    "\n",
    "g = sns.lineplot(data=pandas_df, x=\"window_start\", y=\"num_arrivals\")\n",
    "g.xaxis.set_major_formatter(md.DateFormatter('%d/%m\\n%H:%M'))\n",
    "g.set_title(\"Nombre d'arrivés sur une heure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0be41",
   "metadata": {},
   "source": [
    "### Mode batch sans fenêtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_counts = flights_json \\\n",
    "    .groupBy(\"estDepartureAirport\", \"estArrivalAirport\") \\\n",
    "    .count() \\\n",
    "    .withColumnRenamed(\"count\", \"flight_count\")\n",
    "\n",
    "# Créer un DataFrame pour les arêtes (vols)\n",
    "nbVols = flight_counts.select(\n",
    "    col(\"estDepartureAirport\").alias(\"src\"),\n",
    "    col(\"estArrivalAirport\").alias(\"dst\"),\n",
    "    col(\"flight_count\")\n",
    ")\n",
    "# on se limite au 15 aéroports les plus fréquentés\n",
    "top_n = 15\n",
    "\n",
    "# Identifier les aéroports les plus fréquentés (combinaison de départs et arrivées)\n",
    "top_airports = (\n",
    "    flight_counts.select(\"estDepartureAirport\").union(flight_counts.select(\"estArrivalAirport\"))\n",
    "    .groupBy(\"estDepartureAirport\").count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .limit(top_n)\n",
    "    .select(\"estDepartureAirport\").collect()\n",
    ")\n",
    "top_airport_codes = [row['estDepartureAirport'] for row in top_airports]\n",
    "\n",
    "# Filtrer le dataframe pour n'inclure que les vols entre ces aéroports principaux\n",
    "filtered_counts = flight_counts.filter(\n",
    "    (col(\"estDepartureAirport\").isin(top_airport_codes)) & \n",
    "    (col(\"estArrivalAirport\").isin(top_airport_codes))\n",
    ")\n",
    "\n",
    "filtered_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données qui valent NULL\n",
    "filtered_nbVols = nbVols.filter(\n",
    "    (col(\"src\").isNotNull()) & \n",
    "    (col(\"dst\").isNotNull())\n",
    ")\n",
    "\n",
    "# Trouver les routes les plus empruntées\n",
    "top_routes = filtered_nbVols.orderBy(desc(\"flight_count\")).limit(top_n)\n",
    "top_routes.show()\n",
    "\n",
    "# Convertir en pandas pour visualisation avec Seaborn\n",
    "top_routes_pd = top_routes.toPandas()\n",
    "\n",
    "# Créer des visualisations\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Graphique des routes les plus fréquentées\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=\"flight_count\", y=top_routes_pd.apply(lambda x: f\"{x['src']}-{x['dst']}\", axis=1), \n",
    "            data=top_routes_pd, orient=\"h\")\n",
    "plt.title(\"Routes les plus fréquentées\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"aviation_network_analysis.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db33b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en pandas pour le pivot\n",
    "matrix_data = filtered_counts.toPandas()\n",
    "\n",
    "# Créer la matrice pivot\n",
    "flight_matrix = matrix_data.pivot(index='estDepartureAirport', columns='estArrivalAirport', values='flight_count')\n",
    "flight_matrix = flight_matrix.fillna(0)  # Remplacer les NaN par 0\n",
    "\n",
    "# Créer le heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "ax = sns.heatmap(\n",
    "    flight_matrix,\n",
    "    annot=True,           # Afficher les valeurs\n",
    "    fmt='g',              # Format des nombres (entiers)\n",
    "    cmap='YlGnBu',        # Palette de couleurs (jaune-vert-bleu)\n",
    "    linewidths=0.5,       # Lignes entre les cellules\n",
    "    cbar_kws={'label': 'Nombre de vols'}\n",
    ")\n",
    "\n",
    "# Ajuster les étiquettes et le titre\n",
    "plt.title('Nombre de vols entre les principaux aéroports', fontsize=16)\n",
    "plt.xlabel('Destinations', fontsize=12)\n",
    "plt.ylabel('Origines', fontsize=12)\n",
    "\n",
    "# Rotation des étiquettes pour la lisibilité\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "# Ajuster la mise en page\n",
    "plt.tight_layout()\n",
    "\n",
    "# Sauvegarder et afficher\n",
    "plt.savefig(\"/tmp/flight_heatmap_origin_destination.png\", dpi=300)\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Obtenir quelques statistiques sur cette matrice\n",
    "nonzero_routes = (flight_matrix > 0).sum().sum()\n",
    "total_possible_routes = len(top_airport_codes) * len(top_airport_codes)\n",
    "connectivity_ratio = nonzero_routes / total_possible_routes\n",
    "\n",
    "print(f\"Parmi les {top_n} principaux aéroports:\")\n",
    "print(f\"Nombre total de routes possibles: {total_possible_routes}\")\n",
    "print(f\"Nombre de routes effectivement desservies: {nonzero_routes}\")\n",
    "print(f\"Ratio de connectivité: {connectivity_ratio:.2%}\")\n",
    "print(f\"Nombre moyen de vols par route active: {flight_matrix.sum().sum() / nonzero_routes:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688821c0",
   "metadata": {},
   "source": [
    "## Requête avec SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322bda5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:36.745832Z",
     "start_time": "2025-02-18T12:36:26.714326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enregistrer le DataFrame en tant que table temporaire\n",
    "flights_json.createOrReplaceTempView(\"flights\")\n",
    "\n",
    "# Top 5 de la correspondance la plus fréquente\n",
    "query = \"\"\"\n",
    "SELECT estDepartureAirport, estArrivalAirport, COUNT(*) as count\n",
    "FROM flights\n",
    "WHERE estDepartureAirport IS NOT NULL AND estArrivalAirport IS NOT NULL AND estDepartureAirport != estArrivalAirport\n",
    "GROUP BY estDepartureAirport, estArrivalAirport\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "top_5_couples = sql_context.sql(query)\n",
    "\n",
    "# Afficher les résultats\n",
    "top_5_couples.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f6d4509b615f2",
   "metadata": {},
   "source": [
    "## Requête en mode batch et résultats sous forme de graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687f958118248c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:36.979408Z",
     "start_time": "2025-02-18T12:36:36.755741Z"
    }
   },
   "outputs": [],
   "source": [
    "# Afficher un exemple brut\n",
    "flights_df.selectExpr(\"CAST(value AS STRING)\").show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff94e644396ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:37.047610Z",
     "start_time": "2025-02-18T12:36:36.988311Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_flights = flights_json.filter(\n",
    "    (col(\"estDepartureAirport\").isNotNull()) &\n",
    "    (col(\"estArrivalAirport\").isNotNull())\n",
    ")\n",
    "\n",
    "outbound = filtered_flights.groupBy(\"estDepartureAirport\") \\\n",
    "    .agg(count(\"*\").alias(\"vols_sortants\")) \\\n",
    "    .orderBy(desc(\"vols_sortants\"))\n",
    "\n",
    "inbound = filtered_flights.groupBy(\"estArrivalAirport\") \\\n",
    "    .agg(count(\"*\").alias(\"vols_entrants\")) \\\n",
    "    .orderBy(desc(\"vols_entrants\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c4ef205a02cb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T12:36:41.972571Z",
     "start_time": "2025-02-18T12:36:37.080048Z"
    }
   },
   "outputs": [],
   "source": [
    "outbound_pd = outbound.limit(10).toPandas()\n",
    "inbound_pd = inbound.limit(10).toPandas()\n",
    "\n",
    "# 🎨 Configurer le style Seaborn\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "# 📈 Vols sortants\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    x=\"vols_sortants\",\n",
    "    y=\"estDepartureAirport\",\n",
    "    data=outbound_pd,\n",
    "    palette=\"Blues_r\"\n",
    ")\n",
    "plt.title(\"Top 10 Aéroports - Vols sortants \", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Nombre de vols\")\n",
    "plt.ylabel(\"Aéroport (Départ)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# 📊 Vols entrants\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    x=\"vols_entrants\",\n",
    "    y=\"estArrivalAirport\",\n",
    "    data=inbound_pd,\n",
    "    palette=\"Oranges_r\"\n",
    ")\n",
    "plt.title(\"Top 10 Aéroports - Vols entrants \", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Nombre de vols\")\n",
    "plt.ylabel(\"Aéroport (Arrivée)\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969fb1b4",
   "metadata": {},
   "source": [
    "# Spark streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768e955",
   "metadata": {},
   "source": [
    "## Definir the shema de données states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a176a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType() \\\n",
    "    .add(\"icao24\", StringType()) \\\n",
    "    .add(\"callsign\", StringType()) \\\n",
    "    .add(\"origin_country\", StringType()) \\\n",
    "    .add(\"time_position\", DoubleType()) \\\n",
    "    .add(\"last_contact\", DoubleType()) \\\n",
    "    .add(\"longitude\", DoubleType()) \\\n",
    "    .add(\"latitude\", DoubleType()) \\\n",
    "    .add(\"altitude\", DoubleType()) \\\n",
    "    .add(\"on_ground\", BooleanType()) \\\n",
    "    .add(\"velocity\", DoubleType()) \\\n",
    "    .add(\"heading\", DoubleType()) \\\n",
    "    .add(\"vertical_rate\", DoubleType()) \\\n",
    "    .add(\"sensors\", StringType()) \\\n",
    "    .add(\"geo_altitude\", DoubleType()) \\\n",
    "    .add(\"squawk\", StringType()) \\\n",
    "    .add(\"spi\", BooleanType()) \\\n",
    "    .add(\"position_source\", StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1eaca",
   "metadata": {},
   "source": [
    "## Création des Streaming Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b17453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_flights = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka1:9092\") \\\n",
    "    .option(\"subscribe\", \"opensky_filtered_flights\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "df_filtered_flights = df_filtered_flights.selectExpr(\"CAST(value AS STRING) as json_value\") \\\n",
    "    .select(from_json(col(\"json_value\"), schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\") \\\n",
    "    .withColumn(\"event_time\", current_timestamp())\n",
    "\n",
    "df_filtered_windowed = df_filtered_flights.groupBy(\n",
    "    window(col(\"event_time\"), \"1 minute\"),\n",
    "    col(\"origin_country\")\n",
    ").count()\n",
    "\n",
    "df_bucketed = df_filtered_flights.withColumn(\n",
    "    \"altitude_range\",\n",
    "    when(col(\"altitude\") < 5000, \"Low\")\n",
    "    .when((col(\"altitude\") >= 5000) & (col(\"altitude\") < 15000), \"Medium\")\n",
    "    .otherwise(\"High\")\n",
    ")\n",
    "\n",
    "df_bucket_count = df_bucketed.groupBy(\n",
    "    window(col(\"event_time\"), \"1 minute\"),\n",
    "    col(\"altitude_range\")\n",
    ").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_client import CollectorRegistry, Gauge, push_to_gateway\n",
    "\n",
    "def push_metrics_to_prometheus(df, epoch_id):\n",
    "    registry = CollectorRegistry()\n",
    "    \n",
    "    gauge = Gauge(\n",
    "        'filtered_flights_count', \n",
    "        'Count of filtered flights per country (per 1-minute window)', \n",
    "        ['origin_country'], \n",
    "        registry=registry\n",
    "    )\n",
    "    \n",
    "    for row in df.collect():\n",
    "        country = row['origin_country']\n",
    "        count_val = row['count']\n",
    "        gauge.labels(origin_country=country).set(count_val)\n",
    "    \n",
    "    push_to_gateway('pushgateway:9091', job='spark_filtered_flights', registry=registry)\n",
    "    print(f\"Epoch {epoch_id}: Metrics pushed to Prometheus Pushgateway.\")\n",
    "\n",
    "query_prometheus = df_filtered_windowed.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .foreachBatch(push_metrics_to_prometheus) \\\n",
    "    .start()\n",
    "\n",
    "query_prometheus.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_bucket_metrics(df, epoch_id):\n",
    "    registry = CollectorRegistry()\n",
    "    \n",
    "    gauge = Gauge(\n",
    "        'bucketed_flights_count', \n",
    "        'Count of flights by altitude range per 1-minute window', \n",
    "        ['altitude_range'], \n",
    "        registry=registry\n",
    "    )\n",
    "    \n",
    "    # Iterate over each row in the micro-batch DataFrame.\n",
    "    # Each row should contain the altitude_range and its corresponding count.\n",
    "    for row in df.collect():\n",
    "        bucket = row['altitude_range']\n",
    "        count_val = row['count']\n",
    "        gauge.labels(altitude_range=bucket).set(count_val)\n",
    "    \n",
    "    # Push the metrics to the Pushgateway (ensure the host/port match your configuration)\n",
    "    push_to_gateway('pushgateway:9091', job='spark_bucketed_flights', registry=registry)\n",
    "    print(f\"Epoch {epoch_id}: Bucket metrics pushed to Prometheus Pushgateway.\")\n",
    "\n",
    "# Attach the foreachBatch function to your bucketed query output\n",
    "query_bucket_prom = df_bucket_count.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .foreachBatch(push_bucket_metrics) \\\n",
    "    .start()\n",
    "\n",
    "query_bucket_prom.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb637d61",
   "metadata": {},
   "source": [
    "## Affichage des Streaming Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bucket = df_bucket_count.writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .queryName(\"bucket_console_query\") \\\n",
    "    .start()\n",
    "\n",
    "query_filtered = df_filtered_windowed.writeStream \\\n",
    "    .outputMode(\"update\") \\\n",
    "    .format(\"console\") \\\n",
    "    .queryName(\"filtered_console_query\") \\\n",
    "    .start()\n",
    "\n",
    "# Uncomment the following lines if you wish to block execution:\n",
    "query_bucket.awaitTermination()\n",
    "query_filtered.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
